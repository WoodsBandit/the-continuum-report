# The Continuum Report - Docker Environment Configuration
# Copy this file to .env and fill in your actual values

# =============================================================================
# PAPERLESS-NGX CONFIGURATION (REQUIRED)
# =============================================================================

# Paperless-ngx Server URL
# Inside Docker: http://paperless:8000 (using service name)
# Outside Docker: http://your-host:8040
PAPERLESS_URL=http://paperless:8000

# API Token (REQUIRED)
# Get from: http://your-host:8040 -> Settings -> Admin -> API Tokens
PAPERLESS_TOKEN=

# Paperless Secret Key for internal operations (REQUIRED)
# Generate: openssl rand -base64 32
PAPERLESS_SECRET_KEY=changeme-generate-with-openssl

# Paperless external URL for browser access
PAPERLESS_URL_EXTERNAL=http://localhost:8040

# API request timeout in seconds
PAPERLESS_TIMEOUT=30

# =============================================================================
# OLLAMA CONFIGURATION
# =============================================================================

# Ollama Server URL
# Inside Docker: http://ollama:11434 (using service name)
# Outside Docker: http://your-host:11434
OLLAMA_URL=http://ollama:11434

# LLM Model Name
# Available models: mistral, llama2, neural-chat, zephyr, etc.
# Default: mistral (~4GB)
# Other options:
#   - llama2:7b (~4GB)
#   - neural-chat:7b (~4.1GB)
#   - zephyr:7b (~4.1GB)
#   - openchat:7b (~4GB)
OLLAMA_MODEL=mistral

# Context window size (affects RAM usage)
# Lower values = less RAM, faster processing
# Higher values = more RAM, better context understanding
# Default: 1024 tokens
OLLAMA_CONTEXT_SIZE=1024

# Request timeout in seconds (for long-running queries)
# Default: 600 seconds (10 minutes)
OLLAMA_TIMEOUT=600

# =============================================================================
# CONTINUUM DIRECTORY CONFIGURATION
# =============================================================================

# Base directory for all Continuum data (inside container)
# Default: /continuum
# Don't change unless you modify the Dockerfile
CONTINUUM_BASE_DIR=/continuum

# =============================================================================
# CONTINUUM PROCESSING CONFIGURATION
# =============================================================================

# Maximum documents to search
# Set to high number for no limit
MAX_DOCUMENTS_TO_SEARCH=9999

# Maximum documents to use for entity discovery
# Set to high number for no limit
MAX_DOCUMENTS_FOR_ENTITIES=9999

# Website base URL for generated links
WEBSITE_BASE_URL=https://thecontinuumreport.com

# =============================================================================
# LOGGING CONFIGURATION
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
# Default: INFO
LOG_LEVEL=INFO

# =============================================================================
# DOCKER SETTINGS (for docker-compose)
# =============================================================================

# Compose project name (prefix for container names)
COMPOSE_PROJECT_NAME=continuum

# Container names
COMPOSE_CONTAINER_NAME_SUFFIX=

# =============================================================================
# OPTIONAL: GPU SUPPORT (for Ollama)
# =============================================================================

# Uncomment to enable GPU support in docker-compose.yml
# Requires:
# - NVIDIA GPU with CUDA support
# - nvidia-docker or nvidia-container-toolkit installed
# GPU_DEVICE=0  # GPU device index

# =============================================================================
# OPTIONAL: EXTERNAL SERVICE CONFIGURATION
# =============================================================================

# If running Paperless outside Docker:
# PAPERLESS_URL=http://192.168.1.139:8040
# PAPERLESS_TOKEN=your-external-token

# If running Ollama outside Docker:
# OLLAMA_URL=http://192.168.1.139:11434

# =============================================================================
# OPTIONAL: ADVANCED CONFIGURATION
# =============================================================================

# Python environment variables
PYTHONUNBUFFERED=1
PYTHONDONTWRITEBYTECODE=1
PYTHONHASHSEED=random

# PIP configuration
PIP_NO_CACHE_DIR=1
PIP_DISABLE_PIP_VERSION_CHECK=1

# Timezone (for logging timestamps)
TZ=UTC

# =============================================================================
# NOTES
# =============================================================================

# 1. NEVER COMMIT THIS FILE WITH ACTUAL SECRETS
#    - Add to .gitignore if not already present
#    - Share .env.example instead
#
# 2. REQUIRED FIELDS (must be filled before running):
#    - PAPERLESS_TOKEN (get from Paperless admin)
#    - PAPERLESS_SECRET_KEY (generate with: openssl rand -base64 32)
#
# 3. SECURITY:
#    - Rotate PAPERLESS_SECRET_KEY regularly
#    - Use strong, unique PAPERLESS_TOKEN
#    - Don't share .env file with others
#    - Use Docker secrets for production deployments
#
# 4. PERFORMANCE:
#    - Adjust OLLAMA_CONTEXT_SIZE based on available RAM
#    - Lower context size = faster processing, less RAM
#    - MAX_DOCUMENTS_TO_SEARCH limits batch size
#
# 5. TROUBLESHOOTING:
#    - If services don't connect:
#      docker compose exec continuum curl http://paperless:8000
#    - Check Ollama models:
#      docker compose exec ollama ollama list
#    - View logs:
#      docker compose logs -f continuum
