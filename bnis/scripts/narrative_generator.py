#!/usr/bin/env python3
"""
Narrative Generator for BNIS v2

Uses Claude Code CLI to generate narratives for high-value news items
following The Continuum Report voice guide.

Usage:
    python narrative_generator.py                    # Process latest pending items
    python narrative_generator.py --file pending.json  # Process specific file
    python narrative_generator.py --dry-run          # Show what would be generated
"""

import json
import subprocess
import sys
from datetime import datetime, timezone
from pathlib import Path
from typing import Optional
import argparse

# Base directory
BASE_DIR = Path(__file__).parent.parent.parent

# Directories
PENDING_DIR = BASE_DIR / "pending_summaries"
APPROVED_DIR = BASE_DIR / "pending_approval"
CONFIG_DIR = BASE_DIR / "config"
LOGS_DIR = BASE_DIR / "bnis" / "logs"

# Voice guide for prompt context
VOICE_GUIDE_PATH = CONFIG_DIR / "voice_guide.md"


def load_json(path: Path) -> dict:
    """Load JSON file."""
    if path.exists():
        with open(path, 'r', encoding='utf-8') as f:
            return json.load(f)
    return {}


def save_json(path: Path, data: dict) -> None:
    """Save JSON file."""
    path.parent.mkdir(parents=True, exist_ok=True)
    with open(path, 'w', encoding='utf-8') as f:
        json.dump(data, f, indent=2, ensure_ascii=False)


def load_voice_guide() -> str:
    """Load the voice guide for prompt context."""
    if VOICE_GUIDE_PATH.exists():
        with open(VOICE_GUIDE_PATH, 'r', encoding='utf-8') as f:
            return f.read()
    return ""


def build_prompt(item: dict, voice_guide: str) -> str:
    """
    Build a prompt for Claude Code CLI to generate a narrative.

    Args:
        item: Enriched news item from pipeline
        voice_guide: The Continuum Report voice guide

    Returns:
        Prompt string for Claude Code CLI
    """
    title = item.get("content", {}).get("title", "Untitled")
    text = item.get("content", {}).get("text", "")[:2000]  # Truncate for prompt
    source_url = item.get("source_url", "")
    source_type = item.get("source_type", "unknown")
    published = item.get("published_at", "")

    # Entity matches
    entity_info = item.get("entity_enrichment", {})
    matches = entity_info.get("matches", [])
    entity_names = [m.get("mentioned_name", "") for m in matches[:5]]

    prompt = f"""You are writing for The Continuum Report, an independent intelligence analysis publication.

## Voice Guide (Follow Exactly)

{voice_guide[:3000]}

## Task

Write a breaking news brief for the following story. Follow the template exactly.

## Source Information

- **Title:** {title}
- **Source Type:** {source_type}
- **URL:** {source_url}
- **Published:** {published}
- **Matched Entities:** {', '.join(entity_names) if entity_names else 'None identified'}

## Source Text (Excerpt)

{text}

## Output Template

Generate ONLY the following markdown structure. No additional commentary.

```markdown
## [Write a factual headline with entity names]

**Source:** [Publication/Source], [Date]
**Entities:** [List matched entities]

### Summary

[2-3 sentences summarizing documented facts only]

### Key Details

- [Bullet point with specific claim, cited to source]
- [Another bullet point]
- [Another if relevant]

### Connection to Existing Research

[How this relates to existing Continuum briefs, if entities match manifest]

### Alternative Interpretations

- [One alternative interpretation]
- [Another alternative interpretation]

### Status

- [ ] Pending human review
- [ ] Verified against source
- [ ] Approved for publication

---
*Auto-generated by BNIS. Subject to editorial review.*
```

Generate the brief now:
"""
    return prompt


def call_claude_code(prompt: str, timeout: int = 120) -> Optional[str]:
    """
    Call Claude Code CLI with a prompt.

    Args:
        prompt: The prompt to send
        timeout: Timeout in seconds

    Returns:
        Claude's response or None on error
    """
    try:
        # Write prompt to temp file (handles encoding better)
        temp_prompt = LOGS_DIR / "temp_prompt.txt"
        temp_prompt.parent.mkdir(parents=True, exist_ok=True)
        with open(temp_prompt, 'w', encoding='utf-8') as f:
            f.write(prompt)

        # Call Claude Code CLI
        # Using --print to get just the response
        result = subprocess.run(
            ["claude", "--print", "-p", prompt],
            capture_output=True,
            text=True,
            timeout=timeout,
            encoding='utf-8'
        )

        if result.returncode == 0:
            return result.stdout.strip()
        else:
            print(f"Claude CLI error: {result.stderr}")
            return None

    except subprocess.TimeoutExpired:
        print(f"Claude CLI timed out after {timeout}s")
        return None
    except FileNotFoundError:
        print("Claude CLI not found. Ensure 'claude' is in PATH.")
        return None
    except Exception as e:
        print(f"Error calling Claude CLI: {e}")
        return None


def process_item(item: dict, voice_guide: str, dry_run: bool = False) -> Optional[dict]:
    """
    Process a single item and generate narrative.

    Args:
        item: Enriched news item
        voice_guide: Voice guide content
        dry_run: If True, don't actually call Claude

    Returns:
        Generated narrative dict or None
    """
    item_id = item.get("id", "unknown")
    title = item.get("content", {}).get("title", "Untitled")[:60]

    print(f"\nProcessing: {item_id}")
    print(f"  Title: {title}...")

    if dry_run:
        print("  [DRY RUN] Would generate narrative")
        return {"id": item_id, "status": "dry_run"}

    # Build prompt
    prompt = build_prompt(item, voice_guide)

    # Call Claude
    print("  Calling Claude Code CLI...")
    response = call_claude_code(prompt)

    if response:
        print("  Generated narrative successfully")
        return {
            "id": item_id,
            "source_item": item,
            "narrative": response,
            "generated_at": datetime.now(timezone.utc).isoformat(),
            "status": "pending_review"
        }
    else:
        print("  Failed to generate narrative")
        return None


def find_latest_pending() -> Optional[Path]:
    """Find the most recent pending file."""
    pending_files = list(PENDING_DIR.glob("pending_*.json"))
    if not pending_files:
        return None
    return max(pending_files, key=lambda p: p.stat().st_mtime)


def main():
    parser = argparse.ArgumentParser(description="Generate narratives for BNIS items")
    parser.add_argument("--file", type=str, help="Specific pending file to process")
    parser.add_argument("--dry-run", action="store_true", help="Show what would be processed")
    parser.add_argument("--limit", type=int, default=5, help="Max items to process")
    args = parser.parse_args()

    print("=" * 70)
    print("BNIS Narrative Generator")
    print(f"Timestamp: {datetime.now(timezone.utc).isoformat()}")
    print("=" * 70)

    # Load voice guide
    voice_guide = load_voice_guide()
    if not voice_guide:
        print("Warning: Voice guide not found. Using minimal prompts.")
    else:
        print(f"Loaded voice guide: {len(voice_guide)} chars")

    # Find pending file
    if args.file:
        pending_path = Path(args.file)
    else:
        pending_path = find_latest_pending()

    if not pending_path or not pending_path.exists():
        print("\nNo pending items found.")
        print(f"Run intelligence_pipeline.py first to generate items.")
        return

    print(f"\nProcessing: {pending_path.name}")

    # Load pending items
    pending_data = load_json(pending_path)
    items = pending_data.get("items", [])

    if not items:
        print("No items in pending file.")
        return

    print(f"Found {len(items)} items to process (limit: {args.limit})")

    # Process items
    results = []
    for item in items[:args.limit]:
        result = process_item(item, voice_guide, args.dry_run)
        if result:
            results.append(result)

    # Save results
    if results and not args.dry_run:
        timestamp = datetime.now(timezone.utc).strftime("%Y%m%d_%H%M%S")
        output_file = APPROVED_DIR / f"narratives_{timestamp}.json"
        output_file.parent.mkdir(parents=True, exist_ok=True)

        save_json(output_file, {
            "narratives": results,
            "count": len(results),
            "source_file": str(pending_path),
            "generated_at": datetime.now(timezone.utc).isoformat()
        })
        print(f"\nSaved {len(results)} narratives to: {output_file.name}")

        # Also save individual markdown files
        for result in results:
            if result.get("narrative"):
                md_file = APPROVED_DIR / f"brief_{result['id'][:20]}.md"
                with open(md_file, 'w', encoding='utf-8') as f:
                    f.write(result["narrative"])
                print(f"Saved: {md_file.name}")

    # Summary
    print("\n" + "=" * 70)
    print("Generation Complete")
    print("=" * 70)
    print(f"Processed: {len(items[:args.limit])} items")
    print(f"Generated: {len(results)} narratives")
    if not args.dry_run:
        print(f"Output: {APPROVED_DIR}")
        print("\nNext: Review narratives in pending_approval/")
        print("       Approved briefs go to website/briefs/breaking_news/")


if __name__ == "__main__":
    main()
